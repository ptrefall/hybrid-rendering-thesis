\section{Implementation}

\subsection{Engine architecture}
The architecture of the engine is mainly focused on the concepts of file loading and parsing, object oriented wrapping of OpenGL, scene objects, and render passes.

\subsubsection{File loading and parsing}
\paragraph{BART}
Write something about BART.
\paragraph{Assimp}
Write something about Assimp.
\paragraph{Shaders}
Write something about shader loading.
\paragraph{Textures}
Write something about texture loading.
\paragraph{Materials}
Write something about material loadaing and parsing
\paragraph{Configuration}
Write something about configuration loading and parsing.

\subsubsection{Object oriented OpenGL wrappers}
As was explained in chapter (about OpenGL), the OpenGL API is a stack-based state machine. In an engine architecture, it makes for more robust handling when a certain behavior is grouped or stored within a class, and take advantage of the construction of objects and destruction of objects, to automate the state of the OpenGL stack as much as possible.

\subsubsection{Scene objects}
The scene consist of multiple graphical objects positioned on the screen, and scene objects represents these by declaring the OpenGL render buffers, etc...

\subsubsection{Render pass}
A render pass defines a group of scene objects to be rendered by the rasterizer or raytracer, and can write to render buffers or the back buffer. The SceneManager object defines the order in which the different passes are called, and often one render pass depends on another in order to move down the render pipeline. For instance, the final light pass requires that at least the g-buffer pass has been made in order to work.

\subsection{Deferred pipeline}
The pipeline of the deferred renderer is broken up into two render passes. The G-buffer pass and the final light pass.

\subsubsection{G-buffer pass}
In the G-buffer pass, all geometry in the scene is rendered by the rasterizer. Position, diffuse and normal data is stored in an MRT in view space.

\begin{Verbatim}[frame=single, numbers=left, label=G-buffer vertex shader]
#version 330 core
#define DIFFUSE  0
#define POSITION 1
#define NORMAL   2
#define TEXCOORD 3

uniform mat4 Object_to_World;
uniform mat4 World_to_View;
uniform mat4 View_to_Clip;
uniform mat3 Normal_to_View;

layout(location = POSITION) in vec3 Position_os;
layout(location = NORMAL)   in vec3 Normal_os;
layout(location = TEXCOORD) in vec2 TexCoord;

out gl_PerVertex
{
   vec4 gl_Position;
};

out block
{
   vec4 position_ws; //world space
   vec4 position_vs; //view space
   vec3 normal_vs;   //view space
   vec2 texcoord;
} Vertex;

void main( void )
{	
   Vertex.texcoord = TexCoord;
	
   //Object space to View space
   Vertex.normal_vs = normalize(Normal_to_View * Normal_os);
	
   //Object space to World space
   Vertex.position_ws = Object_to_World * vec4(Position_os, 1.0);
	
   //World  space to View  space
   Vertex.position_vs = World_to_View * Vertex.position_ws;
	
   //View   space to Clip  space
   gl_Position = View_to_Clip  * Vertex.position_vs;
}
\end{Verbatim}

\begin{Verbatim}[frame=single, numbers=left, label=G-buffer fragment shader]
#version 330 core
#define DIFFUSE  0
#define POSITION 1
#define NORMAL   2
#define TEXCOORD 3

uniform sampler2D diffuse_tex;
uniform float material_id;

in block
{
   vec4 position_ws; //world space
   vec4 position_vs; //view space
   vec3 normal_vs;   //view space
   vec2 texcoord;
} Vertex;

layout(location = DIFFUSE,  index = 0) out vec4 out_Diffuse;
layout(location = POSITION, index = 0) out vec4 out_Position;
layout(location = NORMAL,   index = 0) out vec4 out_Normal;

vec4 Diffuse();
vec3 Position();
vec3 Normal();

void main( void )
{
   out_Diffuse  = Diffuse();
   out_Position = vec4(Position(), 1.0);
   out_Normal   = vec4(Normal(),material_id);
}

vec4 Diffuse()
{
   return texture(diffuse_tex, Vertex.texcoord);
}
vec3 Position()
{
   return Vertex.position_vs.xyz;
}
vec3 Normal()
{
   //view space
   vec3 frontNormal_vs = gl_FrontFacing ? 
                         Vertex.normal_vs : -Vertex.normal_vs;
   return normalize(frontNormal_vs);
}
\end{Verbatim}

\subsubsection{Final light pass}
In the Final light pass, a fullscreen quad is rasterized. For each pixel on the screen, each light in the scene interact with what is stored in the G-buffer for that pixel. The result is written to the back-buffer and displayed on the screen.

\begin{Verbatim}[frame=single, numbers=left, label=Final vertex shader]
#version 330 core
#define DIFFUSE  0
#define POSITION 1
#define NORMAL   2
#define TEXCOORD 3

layout(location = POSITION) in vec2 Position;

out gl_PerVertex
{
   vec4 gl_Position;
};

out block
{
   vec2 t; //TexCoord
} Vertex;

void main( void )
{
   vec2 madd = vec2(0.5,0.5);
   vec2 pos_norm = Position; // vertices go from 0,0 to 1,1
   Vertex.t = (pos_norm * madd) + madd; // Scale to 0-1 range
   gl_Position = vec4( Position , 0.0, 1.0);
}
\end{Verbatim}

\begin{Verbatim}[frame=single, numbers=left, label=Final fragment shader]
#version 330 core
#define DIFFUSE    0
#define POSITION   1
#define NORMAL     2
#define TEXCOORD   3
#define FRAG_COLOR 0

uniform sampler2D TEX_DIFF;
uniform sampler2D TEX_POS;
uniform sampler2D TEX_NORM;
uniform sampler2D TEX_RAY;

uniform vec3 ambient_mat[16];
uniform vec3 diffuse_mat[16];
uniform vec3 specular_mat[16];
uniform vec3 pp_t_ior_mat[16];


uniform struct SLight
{
   vec3 position_vs; //view space
} light[1];
uniform vec3 CamPos_vs; //view space

in block
{
   vec2 t; //TexCoord
} Vertex;

layout(location = FRAG_COLOR, index = 0) out vec4 out_FragColor;

float compute_phong_term(in vec3 N, in vec3 L, in vec3 V, 
                         in float NdotL, in float shininess)
{
   vec3 R = reflect(N, -L);
   float term = max(clamp(dot(V,R), 0.0, 1.0), 0.0);
   term = pow(term, shininess);
   return term;
}

float compute_blinn_term(in vec3 N, in vec3 L, in vec3 V, 
                         in float NdotL, in float shininess)
{
   vec3 H = normalize(L + V);
   float term = dot(N,H);
   term = max(clamp(term, 0.0, 1.0), 0.0);
   term = pow(term, shininess);
   return term;
}

float compute_gauss_term(in vec3 N, in vec3 L, in vec3 V, 
                         in float NdotL, in float shininess)
{
   vec3 H = normalize(L+V);
   float ANH = acos(dot(N,H));
   float exponent = ANH / shininess;
   exponent = -(exponent*exponent);
   float term = max(exp(exponent), 0.0);
   return term;
}

void main( void )
{
   vec3 diffuse = texture( TEX_DIFF, Vertex.t ).xyz;
   vec3 position_vs = texture( TEX_POS,  Vertex.t ).xyz;
   vec4 normal_matid = texture( TEX_NORM, Vertex.t );
   int material_id = int(normal_matid.a);
   vec4 ray = texture( TEX_RAY, Vertex.t );
	
   //Rasterized normals commented out
   //vec3 N = normalize(normal_matid.xyz); //view space

   //Use raytraced normals, move from [0,1] to [-1,1]
   vec3 N = normalize(ray.xyz * 2.0 - 1.0); //view space

   vec3 light_pos_vs = light[0].position_vs; //view space
   vec3 L = normalize(light_pos_vs - position_vs); //view space
   vec3 V = normalize(CamPos_vs-position_vs); //view space
	
   float NdotL = max(dot(N,L), 0.0);
   float shininess = pp_t_ior_mat[material_id].r;
	
   //Use gaussian term (could change to phong or blinn term)
   float term = compute_gauss_term(N, L, V, NdotL, shininess);
    
   //out_FragColor = vec4(diffuse, 1.0);
   //out_FragColor = vec4(-position_vs.zzz*0.1, 1.0);
   //out_FragColor = vec4(N * 0.5 - 0.5, 1.0);
   //out_FragColor = vec4(ray.rgb* 2.0 - 1.0,1.0);
    
   out_FragColor = vec4( 
      ((diffuse * diffuse_mat[material_id] * NdotL) + 
      (specular_mat[material_id] * term) + 
      (diffuse * ambient_mat[material_id])), 
      1.0);
}
\end{Verbatim}

\subsection{Camera model}
The raytracer uses pinhole camera model. The eye is a point, rays are cast from this point, through the viewplane and into the scene. Eyepoint-viewplane distance determines focal length. A rasterizer on the other hand requires a projection matrix.

\subsection{Various hybrid configurations}

\subsection{Geometry}
Traditional triangle meshes with vertex attributes (normals, texture coordinates etc)

